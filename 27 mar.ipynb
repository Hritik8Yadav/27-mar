{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc16511e-000e-417f-b981-d5f94142d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans1: The R square is a type of performance matrix which is used to predict the accuracy of the model. It is\n",
    "         the value which we get after calculating the errors or say residual. The two type of values are used\n",
    "         while computing the R square:\n",
    "            \n",
    "            i. Sum of squared residual(SSR) : It is the sum of squred of the values of difference between the actual and\n",
    "                                        calculated values for each instances.\n",
    "            ii. Sum of squared total(SST) : It is the sum of squared of the values of difference between the actual and \n",
    "                                      mean value of target variable for each instance.\n",
    "                    \n",
    "                    The formuala for R sq is: \n",
    "                    \n",
    "                    \n",
    "                                        R(sq) = 1 - SSR\n",
    "                                                    ---\n",
    "                                                    SST\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f7c7a-6a7e-4446-8358-c93b5ac4e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans2: The adjusted R square is the modified version of R squared and it eliminates some of the problems of \n",
    "         R squared and that itself use the value of R squred to calculate the adjusted R square. \n",
    "         The problem in R square is that it doesn't include the number of predictor variables and i.e. why it \n",
    "         sometimes create problem by overcalculating the accuracy.\n",
    "         While in the adjusted r square does take the predictor variables number and predict the accuracy more \n",
    "         accurately.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa3eee-e38f-4706-9729-84add1b7bc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans3: The adjusted R square can be used where the number of independent variables or the features is vary large\n",
    "        And we are using various variables to predict the output and want to measure the accuracy more accurately.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bf81d-595a-49cb-98cb-54e47f48386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans4: MSE: It is the mean of sum of square of difference between the actual value and the calcualted value of the target\n",
    "              variables. And It denotes the mean error in prediction of the target value i.e. square of on an average how \n",
    "              much the calculated value is deviated from the true value.\n",
    "        \n",
    "        MAE: It is called Mean Absolute Error and denotes the mean of sum of absolute differnce between the actual\n",
    "             and the calculated value of the target variables. It denotes the deviation of the target value from the \n",
    "             actual value while in positive side.\n",
    "        \n",
    "        RMSE: It is the Root Mean Squared Error and denotes sqrt of the mean square error But the advantage of RMSE\n",
    "              over MSE is that the unit of the values or the units of error is same as of the feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc66d0b-688c-439f-a5dc-3afe50fbdfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans5: The advantages and disadvantages of MSE, MAE, RMSE are:\n",
    "            \n",
    "        Advantages: \n",
    "            \n",
    "            i. In MSE the equation is differentiable and thus we can find the global minima.\n",
    "            ii. In MAE the unit is same as the feature and is robust to outliers.\n",
    "            iii. In RMSE the unit is same as well as the equation is differentiable.\n",
    "        \n",
    "        Disadvantages:\n",
    "            \n",
    "            i. In MSE the unit is not same as the feature and it is also affected by outliers most.\n",
    "            ii. In MAE the equation is sometime not differntiable and thus need more time to find global minima.\n",
    "            iii. In RMSE it is not robust to outliers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630257c-3a14-4241-8dae-06256688226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans6: The lasso regularisation is a type of regularisation which is used for the feature selection from the \n",
    "         group of the features. It works by using the hyperparameter lambda by changing it. The lasso regularisation\n",
    "         make the equation of the bias more effective as it add the extra parameter (lambda x |slope|) which reduce the\n",
    "         coefficient of the target and make 0 to them which aren't so useful. \n",
    "         \n",
    "         While in Ridge regularisation the lambda is multiplied  by (slope)**2.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bc2db8-c28f-4086-86ef-a478c487edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans7: The regularized linear models does help to reduce the overfitting such as the Ridge regularisation In which\n",
    "         we add the extra computational values to the bias which increase the bias when it tends to zero. By zero\n",
    "         we means the overfitting. when the bias is zero the model follows the exact training data which meke the\n",
    "         model to perform best on the trainging data but this is undesirable and we need some error to be there.\n",
    "         example how Ridge regularisation works:\n",
    "                 \n",
    "                 let's take an example of a linear model which is trained but the model optimise itself to follow the\n",
    "        exact path of the data hence the data is overfitted due to error being zero.\n",
    "        to eliminate this we use the equation of bias as:\n",
    "                        \n",
    "                        cost fun = Σ (1/n) * (y - y_bar) + λ * (slope)**2\n",
    "        \n",
    "        This means the error will not be zero at any cost and hence reduce the overfitting.\n",
    "                 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b46a24f-fed9-4fff-8783-182c71880f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans8: Following are the disadvantages of regularized models: \n",
    "            \n",
    "            i. fexiablity constarins : The regularized models have certain constrains such as in magnitude of the \n",
    "                                        coefficient of variables which limits the flexiablity.\n",
    "            ii. Interpretability: Regularized models can make it difficult to interpret the coefficients of the \n",
    "                                  model, especially when the regularization parameter is large.\n",
    "                                  \n",
    "            iii. Selection of regularization parameter: The performance of a regularized model depends on the \n",
    "                                                        choice of the regularization parameter. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d86d0-a68e-4853-879e-8e60fba3ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans9: We will use the model with RMSE of 10 because the rmse make prediction as the RMSE gives\n",
    "         the priority to the error the errors with lesser values is taken as the lesser priority.\n",
    "         \n",
    "         But the MAE gives more accurate results but the errors are given equal priority and the average is calculated\n",
    "         \n",
    "         We are assuming that there is no outliers in the data present as the RSME is not robust to the outliers.\n",
    "         \n",
    "         \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d105f26d-bde2-417c-85e2-9c5597f9fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ans10: We will use the model with the higher value of regualation paramerter as 0.5 which is lesso regularization\n",
    "          model because the higher is the regularisation value less will the model overfit the data this leads but\n",
    "          this leads to the compromise in the accuracy in the prediction.\n",
    "          \n",
    "          so if the overfitting is not an issue and we need very high accuracy then the Ridge regression model of \n",
    "          perameter value of 0.1 can be used.\n",
    "          \n",
    "          \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
